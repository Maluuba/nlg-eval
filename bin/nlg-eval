#!/usr/bin/env python
#
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT license. See LICENSE.md file in the project root for full license information.

import logging
import os
import stat
import sys
import time
from zipfile import ZipFile

import click

import nlgeval


def _download_file(d):
    import requests
    from tqdm import tqdm

    url, target_dir = d['url'], d['target_dir']
    filename = url[url.rfind('/') + 1:]
    target_path = os.path.join(target_dir, filename)
    if not os.path.exists(target_path):
        # Collect data 1MB at a time.
        chunk_size = 1 * 1024 * 1024
        if not os.path.exists(target_dir):
            os.makedirs(target_dir)

        num_attempts = 3

        for attempt_num in range(num_attempts):
            try:
                print("Downloading {} to {}.".format(url, target_dir))
                r = requests.get(url, stream=True)
                r.raise_for_status()

                total = None
                length = r.headers.get('Content-length')
                if length is not None:
                    total = int(length) // chunk_size + 1

                with open(target_path, 'wb') as f:
                    for chunk in tqdm(r.iter_content(chunk_size=chunk_size),
                                      desc="{}".format(filename),
                                      total=total,
                                      unit_scale=True, mininterval=15, unit=" chunks"):
                        sys.stdout.flush()
                        f.write(chunk)
                break
            except:
                if attempt_num < num_attempts - 1:
                    wait_s = 1 * 60
                    logging.exception("Error downloading file, will retry in %ds.", wait_s)
                    # Wait and try to download later.
                    time.sleep(wait_s)
                else:
                    raise


def setup(ctx, param, value):
    if not value:
        return
    from multiprocessing import Pool

    data_path = os.getenv('NLGEVAL_DATA', 'nlgeval/data')

    path = 'nlgeval/word2vec/glove2word2vec.py'
    if os.path.exists(path):
        os.remove('nlgeval/word2vec/glove2word2vec.py')

    downloads = []

    if sys.version_info[0] == 2:
        downloads.append(dict(
            url='https://raw.githubusercontent.com/manasRK/glove-gensim/42ce46f00e83d3afa028fb6bf17ed3c90ca65fcc/glove2word2vec.py',
            target_dir='nlgeval/word2vec'
        ))
    else:
        downloads.append(dict(
            url='https://raw.githubusercontent.com/robmsmt/glove-gensim/dea5e55f449794567f12c79dc12b7f75339b18ba/glove2word2vec.py',
            target_dir='nlgeval/word2vec'
        ))

    setup_glove = not os.path.exists(os.path.join(data_path, 'glove.6B.300d.model.bin'))
    if setup_glove:
        downloads.append(dict(
            url='http://nlp.stanford.edu/data/glove.6B.zip',
            target_dir=data_path
        ))

    # Skip-thoughts data.
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/dictionary.txt',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/utable.npy',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/btable.npy',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz',
        target_dir=data_path
    ))
    downloads.append(dict(
        url='http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl',
        target_dir=data_path
    ))

    # multi-bleu.perl
    downloads.append(dict(
        url='https://raw.githubusercontent.com/moses-smt/mosesdecoder/b199e654df2a26ea58f234cbb642e89d9c1f269d/scripts/generic/multi-bleu.perl',
        target_dir='nlgeval/multibleu'
    ))

    # Limit the number of threads so that we don't download too much from the same source concurrently.
    pool = Pool(min(4, len(downloads)))
    pool.map(_download_file, downloads)
    pool.close()
    pool.join()

    if setup_glove:
        from nlgeval.word2vec.generate_w2v_files import generate
        z = ZipFile(os.path.join(data_path, 'glove.6B.zip'))
        z.extract('glove.6B.300d.txt', data_path)
        generate()
        for p in [
            os.path.join(data_path, 'glove.6B.zip'),
            os.path.join(data_path, 'glove.6B.300d.txt'),
            os.path.join(data_path, 'glove.6B.300d.model.txt'),
        ]:
            if os.path.exists(p):
                os.remove(p)

    path = 'nlgeval/multibleu/multi-bleu.perl'
    stats = os.stat(path)
    os.chmod(path, stats.st_mode | stat.S_IEXEC)

    ctx.exit()


@click.command()
@click.option('--setup', is_flag=True, callback=setup, expose_value=False, is_eager=True)
@click.option('--references', type=click.Path(exists=True), multiple=True, required=True, help='Path of the reference file. This option can be provided multiple times for multiple reference files.')
@click.option('--hypothesis', type=click.Path(exists=True), required=True, help='Path of the hypothesis file.')
@click.option('--no-overlap', is_flag=True, help='Flag. If provided, word overlap based metrics will not be computed.')
@click.option('--no-skipthoughts', is_flag=True, help='Flag. If provided, skip-thought cosine similarity will not be computed.')
@click.option('--no-glove', is_flag=True, help='Flag. If provided, other word embedding based metrics will not be computed.')
def compute_metrics(hypothesis, references, no_overlap, no_skipthoughts, no_glove):
    nlgeval.compute_metrics(hypothesis, references, no_overlap, no_skipthoughts, no_glove)


if __name__ == '__main__':
    compute_metrics()
